{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ec8b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/surajpawar/Desktop/Keras_NLP'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650649bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6608a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using JAX backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras_core as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0ee873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  9995k      0  0:00:08  0:00:08 --:--:-- 14.1M\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz\n",
    "!# Remove unsupervised examples\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7651ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "imdb_train = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size = BATCH_SIZE\n",
    "\n",
    ")\n",
    "\n",
    "imdb_test = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\",\n",
    "    batch_size = BATCH_SIZE\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d61a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"In the small American town of Meadowvale Dr. Anthony Blake (David Gale, the IMDb listing for this character is wrong it's definitely Dr. Blake not Dr. Blakely) is the director and founder of the famed 'Psychological Research Institute' and also host's a local T.V. programme called 'Independent Thinkers'. He uses this T.V. show to hypnotise the viewers and make them commit acts of violence. Dr. Blake has the help of a large brain with an evil face that uses it's spinal cord as a tail thingy. Usually the brain is just sitting in a tank, eats mice and the odd bad actor, each time it eats someone it gets much bigger. Meanwhile at the local high-school gifted but troublesome teenager Jim Majelewski (Tom Bresnahan) has been caught putting Sodium down the toilets. Jim is sent to Dr. Blake at the PRI for help with his attitude and behavioural problems. While there Dr. Blake hooks Jim up to, well something I'm not actually sure what. This whatever it is, is attached to the brain. At first Jim is able to resist the brain's mind control. The brain feels that Jim is a threat to itself and it's plans. Once out of the PRI Jim starts having bizarre hallucinations and crashes his car. Jim makes it to his waitress girlfriend Janet (Cynthia Preston as Cyndy Preston) but is handed back to Dr. Blake's assistant Verna (George Buza) soon after by Officer Marks (Harry Booker). The brain wants to kill Jim because he is the only one capable of withstanding it's mind control techniques, and with 'Independent Thinkers' going national the brain doesn't want anything or anyone to stop it's evil plan for world domination! Jim quickly realises that the brain is controlling the entire town and he alone must stop the brain, before it takes over the world!<br /><br />Directed by Ed Hunt who calls himself Edward Hunt here, the Brain wasn't as bad as I thought it was going to be. Don't get me wrong as it certainly isn't great either. The script by Barry Pearson tries a stab at satire with the brain washing and mind control by T.V. storyline. It moves along at a fair pace and isn't too boring. No explanation is given for the existence of the brain at all, it's just there and that's it we have to accept it. The story is a little choppy and never fully explores one single element, there's the T.V. mind control, the brain itself, Jim being hunted by the police & his misbehaviour and various other little bits and pieces here and there including a bizarre revelation regarding Dr. Blake that isn't explained at all. Production wise this film looks cheap, and probably was cheap. The acting isn't great but I've seen worse, and what is David Gale doing in this? In fact this role is similar to Gale's role in Re-Animator (1985) even down to his character's deaths in both films. The brain itself at first sits in a tank and starts to grow whenever it eats someone and by the end it is pretty big. Each stage is just made of rubber. It doesn't look particularly good and isn't scary or creepy, just cheap. There's no blood or gore in it apart from a blink and you'll miss it decapitation. The nudity is provided by Dr. Blake's assistant Vivian (Christine Kossak as Christine Kossack) before she gets eaten. The brain had a certain entertainment value for me but I would think most people would dislike it. Maybe worth a watch if you can see it on T.V. for free.\">, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "print(imdb_train.unbatch().take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b070748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.13.0-cp310-cp310-macosx_10_9_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.14,>=2.13.0\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-macosx_10_15_x86_64.whl (216.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow-text) (0.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (16.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.23.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.5.26)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.4.0)\n",
      "Requirement already satisfied: packaging in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (22.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.23.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.7.0)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (65.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.32.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.56.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.38.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.21.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/surajpawar/Desktop/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-text-2.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c5c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/model.h5\n",
      "\u001b[1m17596448/17596448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.5387032,  1.5418267]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")\n",
    "# Note: batched inputs expected so must wrap string in iterable\n",
    "classifier.predict([\"I love modular workflows in keras-nlp!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3967dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 202ms/step - loss: 0.4538 - sparse_categorical_accuracy: 0.7905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46284598112106323, 0.783519983291626]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(imdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa9f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased/v1/vocab.txt\n",
      "\u001b[1m231508/231508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step     \n",
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased/v1/model.h5\n",
      "\u001b[1m17602216/17602216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\",\n",
    "    num_classes = 2\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfd0f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1737s\u001b[0m 1s/step - loss: 0.5186 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.3106 - val_sparse_categorical_accuracy: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_core.src.callbacks.history.History at 0x7fc2fdfb5a20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    imdb_train,\n",
    "    validation_data = imdb_test,\n",
    "    epochs = 1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f21f09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:51:42.339086: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1655s\u001b[0m 1s/step - loss: 0.5185 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.8530\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1465s\u001b[0m 937ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.8808 - val_loss: 0.2963 - val_sparse_categorical_accuracy: 0.8775\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1442s\u001b[0m 923ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9172 - val_loss: 0.3256 - val_sparse_categorical_accuracy: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_core.src.callbacks.history.History at 0x7fc29aa39060>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\n",
    "    \"bert_tiny_en_uncased\",\n",
    "    sequence_length=512,\n",
    ")\n",
    "\n",
    "\n",
    "imdb_train_cached = (\n",
    "    imdb_train.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "imdb_test_cached = (\n",
    "    imdb_test.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\", preprocessor=None, num_classes=2\n",
    ")\n",
    "classifier.fit(\n",
    "    imdb_train_cached,\n",
    "    validation_data=imdb_test_cached,\n",
    "    epochs=3,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562e639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
